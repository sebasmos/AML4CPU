{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf94aaf2-f33e-4359-b8a5-159a325885bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"/media/enc/vera1/sebastian/codes/ARF_STUFF/RESULTS_arf_paper/exp2_final/exp2_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f4047a-e75e-4f88-8625-d2438d98c93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install river==0.21.0\n",
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from pympler import asizeof\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "#from statsmodels.tsa.stattools import adfuller\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "\n",
    "import time\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from river import forest,tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import copy\n",
    "import sys\n",
    "sys.path.insert(0,'../') \n",
    "from pandas import DataFrame, concat\n",
    "from xgboost import XGBRegressor\n",
    "from src.utils import save_timestamps, store_pickle_model, save_predictions\n",
    "import src.misc as misc\n",
    "from src.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "from src.datasets import load_orangepi_data, normalize_data, series_to_supervised, structure, denormalize_predictions\n",
    "from src.metrics import symmetric_mean_absolute_percentage_error, mean_absolute_scaled_error, mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, r2_score, calculate_metrics\n",
    "from src.train import train_xgb_model, test_xgb_model_update, train_river_model, test_river_model, train_sklearn_model, test_sklearn_model, train_sklearn_partial_fit,test_sklearn_partial_fit\n",
    "from src.memory import bytes_to_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf15dcae-6d42-49b9-8ada-e9b42f5fc360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "\n",
    "def process_model_directories(root_dir):\n",
    "    # Define lists to store values\n",
    "    MAE_values = []\n",
    "    RMSE_values = []\n",
    "    SMAPE_values = []\n",
    "    r2_values = []\n",
    "    MASE_values = []\n",
    "    training_time_values = []\n",
    "    inference_time_values = []\n",
    "    model_memory_values = []\n",
    "\n",
    "    model_metrics_path = os.path.join(root_dir, \"model_data.csv\")\n",
    "    model_metrics = pd.read_csv(model_metrics_path)\n",
    "    return model_metrics\n",
    "\n",
    "def arrays_to_dataframe(MAE_array, RMSE_array, SMAPE_array, r2_array, MASE_array,\n",
    "                        training_time_array, inference_time_array, model_memory_array):\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'MAE': MAE_array,\n",
    "        'RMSE': RMSE_array,\n",
    "        'SMAPE': SMAPE_array,\n",
    "        'r2': r2_array,\n",
    "        'MASE': MASE_array,\n",
    "        'Training_time': training_time_array,\n",
    "        'Training_time_log': np.log(training_time_array),\n",
    "        'Inference_time': inference_time_array,\n",
    "        'Inference_time_log': np.log(inference_time_array),\n",
    "        'Model_memory': model_memory_array\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "dfs = []  \n",
    "\n",
    "for subdir in os.listdir(root_dir):\n",
    "        subdir_path = os.path.join(root_dir, subdir)\n",
    "        if os.path.isdir(subdir_path) and not subdir_path.endswith(\".ipynb_checkpoints\"):\n",
    "            models = os.listdir(subdir_path)\n",
    "            for testbed in models:\n",
    "                subdir_path_tb = os.path.join(subdir_path, testbed)\n",
    "                metrics = process_model_directories(subdir_path_tb)\n",
    "                dfs.append(metrics)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b83a4f-3b40-4de0-a864-5a3cfffca96e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">SMAPE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">r2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MASE</th>\n",
       "      <th>Training_time</th>\n",
       "      <th>Inference_time</th>\n",
       "      <th>Model memory (MB)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaptiveRandomForest_ws_12</td>\n",
       "      <td>12</td>\n",
       "      <td>2.459</td>\n",
       "      <td>0.412</td>\n",
       "      <td>7.738</td>\n",
       "      <td>0.555</td>\n",
       "      <td>15.634</td>\n",
       "      <td>2.411</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.107</td>\n",
       "      <td>1701.082</td>\n",
       "      <td>459.056</td>\n",
       "      <td>3345.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaptiveRandomForest_ws_20</td>\n",
       "      <td>20</td>\n",
       "      <td>2.027</td>\n",
       "      <td>0.604</td>\n",
       "      <td>7.196</td>\n",
       "      <td>0.791</td>\n",
       "      <td>13.111</td>\n",
       "      <td>3.562</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.157</td>\n",
       "      <td>2581.919</td>\n",
       "      <td>546.695</td>\n",
       "      <td>3441.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaptiveRandomForest_ws_32</td>\n",
       "      <td>32</td>\n",
       "      <td>1.764</td>\n",
       "      <td>0.686</td>\n",
       "      <td>6.674</td>\n",
       "      <td>1.040</td>\n",
       "      <td>11.601</td>\n",
       "      <td>4.034</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.178</td>\n",
       "      <td>3381.689</td>\n",
       "      <td>674.653</td>\n",
       "      <td>3580.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaptiveRandomForest_ws_6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.141</td>\n",
       "      <td>0.160</td>\n",
       "      <td>8.566</td>\n",
       "      <td>0.291</td>\n",
       "      <td>19.378</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.042</td>\n",
       "      <td>3424.854</td>\n",
       "      <td>949.961</td>\n",
       "      <td>3250.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaptiveRandomForest_ws_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2.759</td>\n",
       "      <td>0.310</td>\n",
       "      <td>8.085</td>\n",
       "      <td>0.456</td>\n",
       "      <td>17.302</td>\n",
       "      <td>1.806</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.081</td>\n",
       "      <td>2507.585</td>\n",
       "      <td>659.296</td>\n",
       "      <td>3293.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HoeffdingAdaptiveTreeRegressor_ws_12</td>\n",
       "      <td>12</td>\n",
       "      <td>3.760</td>\n",
       "      <td>0.105</td>\n",
       "      <td>9.648</td>\n",
       "      <td>0.168</td>\n",
       "      <td>22.579</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.027</td>\n",
       "      <td>199.969</td>\n",
       "      <td>61.087</td>\n",
       "      <td>73.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HoeffdingAdaptiveTreeRegressor_ws_20</td>\n",
       "      <td>20</td>\n",
       "      <td>4.060</td>\n",
       "      <td>0.195</td>\n",
       "      <td>10.729</td>\n",
       "      <td>1.421</td>\n",
       "      <td>23.859</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.054</td>\n",
       "      <td>0.051</td>\n",
       "      <td>141.921</td>\n",
       "      <td>37.968</td>\n",
       "      <td>88.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HoeffdingAdaptiveTreeRegressor_ws_32</td>\n",
       "      <td>32</td>\n",
       "      <td>4.620</td>\n",
       "      <td>0.539</td>\n",
       "      <td>10.985</td>\n",
       "      <td>0.756</td>\n",
       "      <td>25.823</td>\n",
       "      <td>1.680</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.018</td>\n",
       "      <td>1.198</td>\n",
       "      <td>0.140</td>\n",
       "      <td>37.945</td>\n",
       "      <td>11.534</td>\n",
       "      <td>109.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HoeffdingAdaptiveTreeRegressor_ws_6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.675</td>\n",
       "      <td>0.094</td>\n",
       "      <td>9.715</td>\n",
       "      <td>0.867</td>\n",
       "      <td>21.604</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.024</td>\n",
       "      <td>359.075</td>\n",
       "      <td>102.380</td>\n",
       "      <td>75.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HoeffdingAdaptiveTreeRegressor_ws_9</td>\n",
       "      <td>9</td>\n",
       "      <td>3.730</td>\n",
       "      <td>0.114</td>\n",
       "      <td>10.181</td>\n",
       "      <td>1.934</td>\n",
       "      <td>22.277</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.030</td>\n",
       "      <td>255.211</td>\n",
       "      <td>78.337</td>\n",
       "      <td>73.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HoeffdingTreeRegressor_ws_12</td>\n",
       "      <td>12</td>\n",
       "      <td>3.564</td>\n",
       "      <td>0.093</td>\n",
       "      <td>9.105</td>\n",
       "      <td>0.158</td>\n",
       "      <td>21.502</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.024</td>\n",
       "      <td>9.972</td>\n",
       "      <td>4.285</td>\n",
       "      <td>141.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HoeffdingTreeRegressor_ws_20</td>\n",
       "      <td>20</td>\n",
       "      <td>3.538</td>\n",
       "      <td>0.127</td>\n",
       "      <td>9.058</td>\n",
       "      <td>0.144</td>\n",
       "      <td>21.645</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.033</td>\n",
       "      <td>11.818</td>\n",
       "      <td>4.934</td>\n",
       "      <td>145.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HoeffdingTreeRegressor_ws_32</td>\n",
       "      <td>32</td>\n",
       "      <td>3.532</td>\n",
       "      <td>0.142</td>\n",
       "      <td>9.031</td>\n",
       "      <td>0.144</td>\n",
       "      <td>21.814</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.037</td>\n",
       "      <td>17.337</td>\n",
       "      <td>6.018</td>\n",
       "      <td>189.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HoeffdingTreeRegressor_ws_6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.086</td>\n",
       "      <td>9.161</td>\n",
       "      <td>0.147</td>\n",
       "      <td>20.905</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.022</td>\n",
       "      <td>11.755</td>\n",
       "      <td>6.091</td>\n",
       "      <td>165.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HoeffdingTreeRegressor_ws_9</td>\n",
       "      <td>9</td>\n",
       "      <td>3.573</td>\n",
       "      <td>0.093</td>\n",
       "      <td>9.139</td>\n",
       "      <td>0.176</td>\n",
       "      <td>21.345</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.024</td>\n",
       "      <td>9.925</td>\n",
       "      <td>4.459</td>\n",
       "      <td>153.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLP_partialfit_ws_12</td>\n",
       "      <td>12</td>\n",
       "      <td>5.111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.539</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.268</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.049</td>\n",
       "      <td>4.206</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MLP_partialfit_ws_20</td>\n",
       "      <td>20</td>\n",
       "      <td>5.920</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>29.330</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.537</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>4.264</td>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MLP_partialfit_ws_32</td>\n",
       "      <td>32</td>\n",
       "      <td>6.916</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.363</td>\n",
       "      <td>0.000</td>\n",
       "      <td>32.372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.794</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>4.307</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLP_partialfit_ws_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4.451</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.960</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.924</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.157</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.046</td>\n",
       "      <td>4.183</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLP_partialfit_ws_9</td>\n",
       "      <td>9</td>\n",
       "      <td>4.749</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.221</td>\n",
       "      <td>0.000</td>\n",
       "      <td>26.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.234</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>4.188</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PassiveAggressive_ws_12</td>\n",
       "      <td>12</td>\n",
       "      <td>9.185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>38.171</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PassiveAggressive_ws_20</td>\n",
       "      <td>20</td>\n",
       "      <td>9.798</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.201</td>\n",
       "      <td>0.000</td>\n",
       "      <td>39.145</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.543</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PassiveAggressive_ws_32</td>\n",
       "      <td>32</td>\n",
       "      <td>10.152</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.830</td>\n",
       "      <td>0.000</td>\n",
       "      <td>39.898</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.633</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PassiveAggressive_ws_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9.282</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.704</td>\n",
       "      <td>0.000</td>\n",
       "      <td>39.588</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.413</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3.026</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PassiveAggressive_ws_9</td>\n",
       "      <td>9</td>\n",
       "      <td>8.877</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.850</td>\n",
       "      <td>0.000</td>\n",
       "      <td>37.626</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.307</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3.009</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SGDRegressor_ws_12</td>\n",
       "      <td>12</td>\n",
       "      <td>3.906</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.955</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3.035</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SGDRegressor_ws_20</td>\n",
       "      <td>20</td>\n",
       "      <td>3.961</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.976</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.985</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SGDRegressor_ws_32</td>\n",
       "      <td>32</td>\n",
       "      <td>4.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.992</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.520</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SGDRegressor_ws_6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.917</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.958</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.663</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SGDRegressor_ws_9</td>\n",
       "      <td>9</td>\n",
       "      <td>3.900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.950</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3.026</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SRPRegressor_ws_12</td>\n",
       "      <td>12</td>\n",
       "      <td>4.949</td>\n",
       "      <td>0.054</td>\n",
       "      <td>11.281</td>\n",
       "      <td>0.099</td>\n",
       "      <td>24.322</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.286</td>\n",
       "      <td>0.014</td>\n",
       "      <td>41.546</td>\n",
       "      <td>12.170</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SRPRegressor_ws_20</td>\n",
       "      <td>20</td>\n",
       "      <td>5.164</td>\n",
       "      <td>0.044</td>\n",
       "      <td>11.366</td>\n",
       "      <td>0.080</td>\n",
       "      <td>24.859</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.340</td>\n",
       "      <td>0.012</td>\n",
       "      <td>39.057</td>\n",
       "      <td>11.407</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SRPRegressor_ws_32</td>\n",
       "      <td>32</td>\n",
       "      <td>5.376</td>\n",
       "      <td>0.046</td>\n",
       "      <td>11.455</td>\n",
       "      <td>0.084</td>\n",
       "      <td>25.547</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.394</td>\n",
       "      <td>0.012</td>\n",
       "      <td>40.196</td>\n",
       "      <td>11.755</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SRPRegressor_ws_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4.670</td>\n",
       "      <td>0.029</td>\n",
       "      <td>11.130</td>\n",
       "      <td>0.051</td>\n",
       "      <td>23.740</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.214</td>\n",
       "      <td>0.007</td>\n",
       "      <td>42.047</td>\n",
       "      <td>12.620</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SRPRegressor_ws_9</td>\n",
       "      <td>9</td>\n",
       "      <td>4.833</td>\n",
       "      <td>0.034</td>\n",
       "      <td>11.224</td>\n",
       "      <td>0.049</td>\n",
       "      <td>24.081</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.256</td>\n",
       "      <td>0.009</td>\n",
       "      <td>39.897</td>\n",
       "      <td>11.719</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGBRegressor_ws_12</td>\n",
       "      <td>12</td>\n",
       "      <td>4.082</td>\n",
       "      <td>0.084</td>\n",
       "      <td>9.666</td>\n",
       "      <td>0.100</td>\n",
       "      <td>23.022</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.060</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.161</td>\n",
       "      <td>1297.751</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBRegressor_ws_20</td>\n",
       "      <td>20</td>\n",
       "      <td>4.174</td>\n",
       "      <td>0.099</td>\n",
       "      <td>9.679</td>\n",
       "      <td>0.098</td>\n",
       "      <td>23.411</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.084</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.313</td>\n",
       "      <td>1466.184</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBRegressor_ws_32</td>\n",
       "      <td>32</td>\n",
       "      <td>4.288</td>\n",
       "      <td>0.109</td>\n",
       "      <td>9.730</td>\n",
       "      <td>0.111</td>\n",
       "      <td>23.951</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.112</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.202</td>\n",
       "      <td>1832.652</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBRegressor_ws_6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.923</td>\n",
       "      <td>0.061</td>\n",
       "      <td>9.554</td>\n",
       "      <td>0.068</td>\n",
       "      <td>22.598</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.275</td>\n",
       "      <td>948.860</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBRegressor_ws_9</td>\n",
       "      <td>9</td>\n",
       "      <td>3.995</td>\n",
       "      <td>0.080</td>\n",
       "      <td>9.593</td>\n",
       "      <td>0.082</td>\n",
       "      <td>22.651</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.038</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.622</td>\n",
       "      <td>1258.465</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Window Size     MAE           RMSE  \\\n",
       "                                                        mean    std    mean   \n",
       "0             AdaptiveRandomForest_ws_12          12   2.459  0.412   7.738   \n",
       "1             AdaptiveRandomForest_ws_20          20   2.027  0.604   7.196   \n",
       "2             AdaptiveRandomForest_ws_32          32   1.764  0.686   6.674   \n",
       "3              AdaptiveRandomForest_ws_6           6   3.141  0.160   8.566   \n",
       "4              AdaptiveRandomForest_ws_9           9   2.759  0.310   8.085   \n",
       "5   HoeffdingAdaptiveTreeRegressor_ws_12          12   3.760  0.105   9.648   \n",
       "6   HoeffdingAdaptiveTreeRegressor_ws_20          20   4.060  0.195  10.729   \n",
       "7   HoeffdingAdaptiveTreeRegressor_ws_32          32   4.620  0.539  10.985   \n",
       "8    HoeffdingAdaptiveTreeRegressor_ws_6           6   3.675  0.094   9.715   \n",
       "9    HoeffdingAdaptiveTreeRegressor_ws_9           9   3.730  0.114  10.181   \n",
       "10          HoeffdingTreeRegressor_ws_12          12   3.564  0.093   9.105   \n",
       "11          HoeffdingTreeRegressor_ws_20          20   3.538  0.127   9.058   \n",
       "12          HoeffdingTreeRegressor_ws_32          32   3.532  0.142   9.031   \n",
       "13           HoeffdingTreeRegressor_ws_6           6   3.558  0.086   9.161   \n",
       "14           HoeffdingTreeRegressor_ws_9           9   3.573  0.093   9.139   \n",
       "15                  MLP_partialfit_ws_12          12   5.111  0.000  10.539   \n",
       "16                  MLP_partialfit_ws_20          20   5.920  0.000  11.440   \n",
       "17                  MLP_partialfit_ws_32          32   6.916  0.000  12.363   \n",
       "18                   MLP_partialfit_ws_6           6   4.451  0.000   9.960   \n",
       "19                   MLP_partialfit_ws_9           9   4.749  0.000  10.221   \n",
       "20               PassiveAggressive_ws_12          12   9.185  0.000  18.426   \n",
       "21               PassiveAggressive_ws_20          20   9.798  0.000  18.201   \n",
       "22               PassiveAggressive_ws_32          32  10.152  0.000  17.830   \n",
       "23                PassiveAggressive_ws_6           6   9.282  0.000  18.704   \n",
       "24                PassiveAggressive_ws_9           9   8.877  0.000  17.850   \n",
       "25                    SGDRegressor_ws_12          12   3.906  0.000   9.955   \n",
       "26                    SGDRegressor_ws_20          20   3.961  0.000   9.976   \n",
       "27                    SGDRegressor_ws_32          32   4.006  0.000   9.992   \n",
       "28                     SGDRegressor_ws_6           6   3.917  0.000   9.958   \n",
       "29                     SGDRegressor_ws_9           9   3.900  0.000   9.950   \n",
       "30                    SRPRegressor_ws_12          12   4.949  0.054  11.281   \n",
       "31                    SRPRegressor_ws_20          20   5.164  0.044  11.366   \n",
       "32                    SRPRegressor_ws_32          32   5.376  0.046  11.455   \n",
       "33                     SRPRegressor_ws_6           6   4.670  0.029  11.130   \n",
       "34                     SRPRegressor_ws_9           9   4.833  0.034  11.224   \n",
       "35                    XGBRegressor_ws_12          12   4.082  0.084   9.666   \n",
       "36                    XGBRegressor_ws_20          20   4.174  0.099   9.679   \n",
       "37                    XGBRegressor_ws_32          32   4.288  0.109   9.730   \n",
       "38                     XGBRegressor_ws_6           6   3.923  0.061   9.554   \n",
       "39                     XGBRegressor_ws_9           9   3.995  0.080   9.593   \n",
       "\n",
       "            SMAPE            r2          MASE        Training_time  \\\n",
       "      std    mean    std   mean    std   mean    std          mean   \n",
       "0   0.555  15.634  2.411  0.936  0.009  0.639  0.107      1701.082   \n",
       "1   0.791  13.111  3.562  0.944  0.013  0.526  0.157      2581.919   \n",
       "2   1.040  11.601  4.034  0.951  0.015  0.458  0.178      3381.689   \n",
       "3   0.291  19.378  0.985  0.921  0.005  0.816  0.042      3424.854   \n",
       "4   0.456  17.302  1.806  0.930  0.008  0.717  0.081      2507.585   \n",
       "5   0.168  22.579  0.346  0.901  0.003  0.977  0.027       199.969   \n",
       "6   1.421  23.859  0.554  0.875  0.037  1.054  0.051       141.921   \n",
       "7   0.756  25.823  1.680  0.871  0.018  1.198  0.140        37.945   \n",
       "8   0.867  21.604  0.767  0.898  0.021  0.955  0.024       359.075   \n",
       "9   1.934  22.277  0.602  0.885  0.053  0.969  0.030       255.211   \n",
       "10  0.158  21.502  0.306  0.911  0.003  0.926  0.024         9.972   \n",
       "11  0.144  21.645  0.558  0.912  0.003  0.918  0.033        11.818   \n",
       "12  0.144  21.814  0.718  0.913  0.003  0.916  0.037        17.337   \n",
       "13  0.147  20.905  0.185  0.910  0.003  0.925  0.022        11.755   \n",
       "14  0.176  21.345  0.200  0.911  0.003  0.928  0.024         9.925   \n",
       "15  0.000  27.268  0.000  0.881  0.000  1.328  0.000         0.049   \n",
       "16  0.000  29.330  0.000  0.860  0.000  1.537  0.000         0.100   \n",
       "17  0.000  32.372  0.000  0.837  0.000  1.794  0.000         0.109   \n",
       "18  0.000  24.924  0.000  0.894  0.000  1.157  0.000         0.046   \n",
       "19  0.000  26.100  0.000  0.888  0.000  1.234  0.000         0.047   \n",
       "20  0.000  38.171  0.000  0.637  0.000  2.386  0.000         0.002   \n",
       "21  0.000  39.145  0.000  0.646  0.000  2.543  0.000         0.003   \n",
       "22  0.000  39.898  0.000  0.661  0.000  2.633  0.000         0.004   \n",
       "23  0.000  39.588  0.000  0.626  0.000  2.413  0.000         0.002   \n",
       "24  0.000  37.626  0.000  0.659  0.000  2.307  0.000         0.002   \n",
       "25  0.000  22.005  0.000  0.894  0.000  1.015  0.000         0.003   \n",
       "26  0.000  21.985  0.000  0.894  0.000  1.028  0.000         0.003   \n",
       "27  0.000  22.520  0.000  0.894  0.000  1.039  0.000         0.004   \n",
       "28  0.000  21.663  0.000  0.894  0.000  1.018  0.000         0.002   \n",
       "29  0.000  21.563  0.000  0.894  0.000  1.013  0.000         0.002   \n",
       "30  0.099  24.322  0.172  0.864  0.002  1.286  0.014        41.546   \n",
       "31  0.080  24.859  0.179  0.862  0.002  1.340  0.012        39.057   \n",
       "32  0.084  25.547  0.170  0.860  0.002  1.394  0.012        40.196   \n",
       "33  0.051  23.740  0.164  0.868  0.001  1.214  0.007        42.047   \n",
       "34  0.049  24.081  0.161  0.865  0.001  1.256  0.009        39.897   \n",
       "35  0.100  23.022  0.294  0.900  0.002  1.060  0.022         0.161   \n",
       "36  0.098  23.411  0.420  0.900  0.002  1.084  0.026         0.313   \n",
       "37  0.111  23.951  0.602  0.899  0.002  1.112  0.028         0.202   \n",
       "38  0.068  22.598  0.284  0.902  0.001  1.020  0.016         0.275   \n",
       "39  0.082  22.651  0.327  0.902  0.002  1.038  0.021         0.622   \n",
       "\n",
       "   Inference_time Model memory (MB)  \n",
       "             mean              mean  \n",
       "0         459.056          3345.366  \n",
       "1         546.695          3441.820  \n",
       "2         674.653          3580.965  \n",
       "3         949.961          3250.484  \n",
       "4         659.296          3293.017  \n",
       "5          61.087            73.515  \n",
       "6          37.968            88.252  \n",
       "7          11.534           109.491  \n",
       "8         102.380            75.940  \n",
       "9          78.337            73.479  \n",
       "10          4.285           141.840  \n",
       "11          4.934           145.891  \n",
       "12          6.018           189.327  \n",
       "13          6.091           165.055  \n",
       "14          4.459           153.521  \n",
       "15          4.206             0.347  \n",
       "16          4.264             0.365  \n",
       "17          4.307             0.392  \n",
       "18          4.183             0.333  \n",
       "19          4.188             0.340  \n",
       "20          3.013             0.004  \n",
       "21          3.017             0.004  \n",
       "22          3.017             0.004  \n",
       "23          3.026             0.003  \n",
       "24          3.009             0.003  \n",
       "25          3.035             0.004  \n",
       "26          3.025             0.004  \n",
       "27          3.018             0.004  \n",
       "28          3.029             0.004  \n",
       "29          3.026             0.004  \n",
       "30         12.170             0.166  \n",
       "31         11.407             0.147  \n",
       "32         11.755             0.146  \n",
       "33         12.620             0.154  \n",
       "34         11.719             0.154  \n",
       "35       1297.751             0.004  \n",
       "36       1466.184             0.004  \n",
       "37       1832.652             0.004  \n",
       "38        948.860             0.004  \n",
       "39       1258.465             0.004  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = combined_df.groupby(['Model', 'Window Size']).agg({\n",
    "                                                                     #'MAPE' :['mean', 'std'],\n",
    "                                                                     #'MSE'  :['mean', 'std'],\n",
    "                                                                     'MAE'  :['mean', 'std'],\n",
    "                                                                     'RMSE' :['mean', 'std'],\n",
    "                                                                     'SMAPE':['mean', 'std'],\n",
    "                                                                     'r2'   :['mean', 'std'],\n",
    "                                                                     'MASE' :['mean', 'std'],\n",
    "                                                                     'Training_time' :['mean'],\n",
    "                                                                     'Inference_time' :['mean'],\n",
    "                                                                     'Model memory (MB)' :['mean'],\n",
    "                                                                      }).reset_index()\n",
    "summary = summary.round(3)\n",
    "summary.to_csv(f'{root_dir}/model_metrics_avg.csv', index=False)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundational",
   "language": "python",
   "name": "foundational"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
